# Tendoo Customer Support Chatbot

Chatbot h·ªó tr·ª£ kh√°ch h√†ng v·ªÅ Tendoo App s·ª≠ d·ª•ng RAG (Retrieval-Augmented Generation).

## T√≠nh nƒÉng

### üéØ T√≠nh nƒÉng ch√≠nh
- **H·ªèi ƒë√°p th√¥ng minh**: Tr·∫£ l·ªùi c√¢u h·ªèi v·ªÅ Tendoo App
- **Hybrid Search**: K·∫øt h·ª£p Dense (embedding) + Sparse (BM25)
- **Graph Enrichment**: T·ª± ƒë·ªông b·ªï sung context t·ª´ parent/children/siblings
- **LLM Reranking**: S·∫Øp x·∫øp l·∫°i chunks theo m·ª©c ƒë·ªô li√™n quan
- **Multilingual**: H·ªó tr·ª£ ti·∫øng Vi·ªát t·ªët

### üîß C√¥ng ngh·ªá
- **LLM**: Gemini 2.0 Flash (nhanh, mi·ªÖn ph√≠)
- **Embedding**: BGE-M3 (multilingual, qua Ollama)
- **Framework**: FastAPI
- **RAG**: Advanced v·ªõi nhi·ªÅu t√≠nh nƒÉng t·ªëi ∆∞u

## C√†i ƒë·∫∑t

### Y√™u c·∫ßu
```bash
# Python packages
pip install fastapi uvicorn google-generativeai scikit-learn numpy

# Ollama (cho embeddings)
# T·∫£i t·ª´: https://ollama.ai/
ollama pull bge-m3
```

### Chu·∫©n b·ªã d·ªØ li·ªáu
Tr∆∞·ªõc ti√™n, c·∫ßn t·∫°o chunks t·ª´ t√†i li·ªáu:
```bash
cd backend_v3

# T·∫°o file m·∫´u
/home/admin123/miniconda3/envs/py310/bin/python create_tendoo_sample.py

# Ch·∫°y chunking
/home/admin123/miniconda3/envs/py310/bin/python test_tendoo.py
```

K·∫øt qu·∫£ s·∫Ω ƒë∆∞·ª£c l∆∞u t·∫°i: `output_tendoo/chunks.json`

## S·ª≠ d·ª•ng

### B∆∞·ªõc 1: Kh·ªüi ƒë·ªông Chatbot Server

```bash
# C√°ch 1: Ch·∫°y tr·ª±c ti·∫øp
/home/admin123/miniconda3/envs/py310/bin/python tendoo_chatbot.py

# C√°ch 2: D√πng uvicorn
uvicorn tendoo_chatbot:app --reload --port 8002
```

Server s·∫Ω ch·∫°y t·∫°i: **http://localhost:8002**

Output khi kh·ªüi ƒë·ªông:
```
================================================================================
KH·ªûI ƒê·ªòNG TENDOO CUSTOMER SUPPORT CHATBOT
================================================================================

‚úÖ ƒê√£ load 105 chunks t·ª´ output_tendoo/chunks.json

üîÑ ƒêang t·∫°o embeddings cho chunks...
  ƒê√£ embed 10/105 chunks
  ƒê√£ embed 20/105 chunks
  ...
‚úÖ ƒê√£ t·∫°o 105 embeddings

‚úÖ Chatbot s·∫µn s√†ng ph·ª•c v·ª•!
üìä 105 chunks ƒë√£ ƒë∆∞·ª£c load
ü§ñ Model: gemini-2.0-flash-exp
üîç Embedding: bge-m3
================================================================================
```

### B∆∞·ªõc 2: Test Chatbot

M·ªü terminal m·ªõi v√† ch·∫°y:
```bash
/home/admin123/miniconda3/envs/py310/bin/python test_chatbot.py
```

Script s·∫Ω:
1. Ki·ªÉm tra server ƒëang ch·∫°y
2. Test v·ªõi 5 c√¢u h·ªèi m·∫´u
3. Chuy·ªÉn sang ch·∫ø ƒë·ªô t∆∞∆°ng t√°c

## API Endpoints

### 1. Health Check
```bash
GET http://localhost:8002/

Response:
{
  "status": "ok",
  "service": "Tendoo Customer Support Chatbot",
  "version": "1.0",
  "chunks_loaded": 105,
  "embeddings_created": 105,
  "model": "gemini-2.0-flash-exp"
}
```

### 2. Chat (Main API)
```bash
POST http://localhost:8002/chat

Request:
{
  "query": "L√†m th·∫ø n√†o ƒë·ªÉ c√†i ƒë·∫∑t th√¥ng tin c·ª≠a h√†ng?",
  "conversation_id": "optional-id",
  "include_history": false
}

Response:
{
  "answer": "ƒê·ªÉ c·∫≠p nh·∫≠t th√¥ng tin c·ª≠a h√†ng trong Tendoo App, b·∫°n l√†m theo c√°c b∆∞·ªõc sau:\n\n1. V√†o menu C√†i ƒë·∫∑t > C·ª≠a h√†ng > Th√¥ng tin c·ª≠a h√†ng\n2. ƒêi·ªÅn c√°c th√¥ng tin sau:\n   - T√™n c·ª≠a h√†ng\n   - ƒê·ªãa ch·ªâ\n   - S·ªë ƒëi·ªán tho·∫°i\n   - Email li√™n h·ªá\n3. Nh·∫•n n√∫t L∆∞u ƒë·ªÉ ho√†n t·∫•t\n\n‚ö†Ô∏è L∆∞u √Ω:\n- T√™n c·ª≠a h√†ng s·∫Ω hi·ªÉn th·ªã tr√™n h√≥a ƒë∆°n\n- Email s·∫Ω ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ nh·∫≠n th√¥ng b√°o\n\nB·∫°n c√≤n th·∫Øc m·∫Øc g√¨ kh√°c kh√¥ng?",
  "retrieved_chunks": [
    {
      "chunk_id": "abc123",
      "section_code": "1.1.1",
      "section_title": "Th√¥ng tin c·ª≠a h√†ng",
      "content": "ƒê·ªÉ c·∫≠p nh·∫≠t th√¥ng tin c·ª≠a h√†ng...",
      "score": 0.8523,
      "title_path": "C√†i ƒë·∫∑t c·ª≠a h√†ng > C·ª≠a h√†ng > Th√¥ng tin c·ª≠a h√†ng"
    }
  ],
  "metadata": {
    "total_retrieved": 10,
    "total_enriched": 25,
    "total_used": 15,
    "hybrid_search": true,
    "graph_enrichment": true,
    "reranking": true
  }
}
```

### 3. Stats
```bash
GET http://localhost:8002/stats

Response:
{
  "total_chunks": 105,
  "by_section_type": {
    "section_1": 2,
    "section_2": 4,
    "section_3": 7,
    "item_number": 45,
    "item_dash": 32
  },
  "by_level": {...},
  "top_tags": {
    "c√†i ƒë·∫∑t": 10,
    "b√°n h√†ng": 8
  },
  "config": {
    "llm_model": "gemini-2.0-flash-exp",
    "embedding_model": "bge-m3",
    "hybrid_search": true,
    "graph_enrichment": true,
    "reranking": true
  }
}
```

## V√≠ d·ª• s·ª≠ d·ª•ng

### Python
```python
import requests

url = "http://localhost:8002/chat"
payload = {
    "query": "Tendoo h·ªó tr·ª£ nh·ªØng ph∆∞∆°ng th·ª©c thanh to√°n n√†o?"
}

response = requests.post(url, json=payload)
data = response.json()

print("Tr·∫£ l·ªùi:", data["answer"])
```

### cURL
```bash
curl -X POST http://localhost:8002/chat \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Quy tr√¨nh b√°n h√†ng cho shop FnB nh∆∞ th·∫ø n√†o?"
  }'
```

### JavaScript
```javascript
const response = await fetch('http://localhost:8002/chat', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    query: 'C√≥ nh·ªØng m·∫´u h√≥a ƒë∆°n n√†o?'
  })
});

const data = await response.json();
console.log('Answer:', data.answer);
```

## C√¢u h·ªèi m·∫´u

1. **V·ªÅ c√†i ƒë·∫∑t:**
   - "L√†m th·∫ø n√†o ƒë·ªÉ c√†i ƒë·∫∑t th√¥ng tin c·ª≠a h√†ng?"
   - "C√°ch c·∫•u h√¨nh ph∆∞∆°ng th·ª©c thanh to√°n?"
   - "L√†m sao ƒë·ªÉ t·∫°o website b√°n h√†ng?"

2. **V·ªÅ b√°n h√†ng:**
   - "Quy tr√¨nh b√°n h√†ng cho shop FnB nh∆∞ th·∫ø n√†o?"
   - "C√°c b∆∞·ªõc b√°n h√†ng cho shop b√°n l·∫ª?"
   - "C√°ch √°p d·ª•ng khuy·∫øn m√£i?"

3. **V·ªÅ s·∫£n ph·∫©m:**
   - "Th√¥ng tin s·∫£n ph·∫©m c·∫ßn c√≥ nh·ªØng g√¨?"
   - "C√°ch qu·∫£n l√Ω t·ªìn kho?"
   - "L√†m sao ƒë·ªÉ nh·∫≠p h√†ng v√†o kho?"

4. **V·ªÅ h√≥a ƒë∆°n:**
   - "C√≥ nh·ªØng m·∫´u h√≥a ƒë∆°n n√†o?"
   - "S·ª± kh√°c bi·ªát gi·ªØa c√°c m·∫´u h√≥a ƒë∆°n?"
   - "M·∫´u h√≥a ƒë∆°n n√†o ph√π h·ª£p v·ªõi shop c·ªßa t√¥i?"

## T√πy ch·ªânh

### Thay ƒë·ªïi s·ªë l∆∞·ª£ng chunks
Trong `tendoo_chatbot.py`:
```python
class Config:
    TOP_K = 5  # S·ªë chunks retrieve
    MAX_DESCENDANTS = 5  # S·ªë children
    MAX_SIBLINGS = 3  # S·ªë siblings
    RERANK_TOP_K = 3  # S·ªë chunks sau rerank
```

### B·∫≠t/t·∫Øt t√≠nh nƒÉng
```python
class Config:
    USE_HYBRID_SEARCH = True  # Hybrid search
    USE_GRAPH_ENRICHMENT = True  # Include parent/children
    USE_RERANKING = True  # LLM reranking
```

### Thay ƒë·ªïi model
```python
class Config:
    LLM_MODEL = "gemini-2.0-flash-exp"  # Ho·∫∑c "gemini-1.5-pro"
    EMBEDDING_MODEL = "bge-m3"  # Ho·∫∑c model kh√°c t·ª´ Ollama
```

### T√πy ch·ªânh prompt
S·ª≠a h√†m `generate_answer()` trong `tendoo_chatbot.py`:
```python
prompt = f"""B·∫°n l√† tr·ª£ l√Ω AI...
[S·ª≠a prompt c·ªßa b·∫°n ·ªü ƒë√¢y]
"""
```

## Troubleshooting

### L·ªói: "Chunks ch∆∞a ƒë∆∞·ª£c load"
**Nguy√™n nh√¢n:** File `output_tendoo/chunks.json` kh√¥ng t·ªìn t·∫°i.

**Gi·∫£i ph√°p:**
```bash
python test_tendoo.py  # T·∫°o chunks tr∆∞·ªõc
```

### L·ªói: "Cannot connect to Ollama"
**Nguy√™n nh√¢n:** Ollama ch∆∞a ch·∫°y ho·∫∑c ch∆∞a c√≥ model bge-m3.

**Gi·∫£i ph√°p:**
```bash
# Ki·ªÉm tra Ollama
ollama list

# Pull model n·∫øu ch∆∞a c√≥
ollama pull bge-m3
```

### L·ªói: "Gemini API key invalid"
**Nguy√™n nh√¢n:** API key kh√¥ng h·ª£p l·ªá.

**Gi·∫£i ph√°p:**
C·∫≠p nh·∫≠t API key trong `tendoo_chatbot.py`:
```python
class Config:
    GEMINI_API_KEY = "your-api-key-here"
```

### Server ch·∫≠m
**Nguy√™n nh√¢n:** Embedding/LLM m·∫•t th·ªùi gian.

**Gi·∫£i ph√°p:**
- Gi·∫£m `TOP_K` xu·ªëng 3
- T·∫Øt `USE_RERANKING = False`
- Gi·∫£m `MAX_DESCENDANTS` v√† `MAX_SIBLINGS`

## Performance

### Th·ªùi gian x·ª≠ l√Ω (trung b√¨nh)
- **Embedding query**: ~100ms
- **Hybrid search**: ~50ms
- **Graph enrichment**: ~20ms
- **LLM reranking**: ~500ms (n·∫øu b·∫≠t)
- **Generate answer**: ~2-3s (Gemini)

**T·ªïng**: ~3-4s/query (v·ªõi reranking), ~2-3s (kh√¥ng reranking)

### T·ªëi ∆∞u h√≥a
ƒê·ªÉ tƒÉng t·ªëc ƒë·ªô:
1. T·∫Øt reranking: `USE_RERANKING = False`
2. Gi·∫£m s·ªë chunks: `TOP_K = 3`
3. Gi·∫£m context: `MAX_DESCENDANTS = 2`, `MAX_SIBLINGS = 1`
4. S·ª≠ d·ª•ng model nh·ªè h∆°n cho Gemini

## License

MIT

## Contact

N·∫øu c√≥ v·∫•n ƒë·ªÅ, vui l√≤ng t·∫°o issue ho·∫∑c li√™n h·ªá support team.
